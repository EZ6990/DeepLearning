{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleHomeDepot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EZ6990/DeepLearning/blob/master/KaggleHomeDepot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcWETgmj4eMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"bgudltaldanny\",\"key\":\"65b62f1a36c14c834b4e88037463a4f8\"}\n",
        "with open('.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKXPhN_vv3hJ",
        "colab_type": "code",
        "outputId": "00b8f0f2-6c4f-477a-9c6d-b823fa7284fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        }
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "\n",
        "\n",
        "!kaggle competitions download -c home-depot-product-search-relevance\n",
        "!unzip home-depot-product-search-relevance.zip -d home-depot-product-search-relevance/\n",
        "!unzip home-depot-product-search-relevance/train.csv.zip -d home-depot-product-search-relevance/\n",
        "!unzip home-depot-product-search-relevance/test.csv.zip -d home-depot-product-search-relevance/"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chmod: cannot access '/root/.kaggle/kaggle.json': No such file or directory\n",
            "Found existing installation: kaggle 1.5.6\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
            "Processing /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01/kaggle-1.5.6-py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.28.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.6.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.21.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2019.11.28)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/kaggle\", line 5, in <module>\n",
            "    from kaggle.cli import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/__init__.py\", line 23, in <module>\n",
            "    api.authenticate()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/kaggle/api/kaggle_api_extended.py\", line 149, in authenticate\n",
            "    self.config_file, self.config_dir))\n",
            "OSError: Could not find kaggle.json. Make sure it's located in /root/.kaggle. Or use the environment method.\n",
            "unzip:  cannot find or open home-depot-product-search-relevance.zip, home-depot-product-search-relevance.zip.zip or home-depot-product-search-relevance.zip.ZIP.\n",
            "unzip:  cannot find or open home-depot-product-search-relevance/train.csv.zip, home-depot-product-search-relevance/train.csv.zip.zip or home-depot-product-search-relevance/train.csv.zip.ZIP.\n",
            "unzip:  cannot find or open home-depot-product-search-relevance/test.csv.zip, home-depot-product-search-relevance/test.csv.zip.zip or home-depot-product-search-relevance/test.csv.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r10iXLp-DFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "1faa01f9-466f-4b88-a0fc-ae7af264f4ab"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout,Conv1D, MaxPool1D,Concatenate, LSTM, Reshape, CuDNNLSTM, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "import keras.backend as K\n",
        "from sklearn.pipeline import Pipeline,FeatureUnion,make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer,KBinsDiscretizer,OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score,cross_val_predict,cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.regularizers import l2\n",
        "from scipy import spatial\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaItXIaqBPac",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "f15ba73e-24b3-4d34-ca15-06f7d3d61013"
      },
      "source": [
        "path='./home-depot-product-search-relevance'\n",
        "train=pd.read_csv(path+'/train.csv',encoding=\"Latin-1\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3dd88a6c9d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./home-depot-product-search-relevance'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Latin-1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'./home-depot-product-search-relevance/train.csv' does not exist: b'./home-depot-product-search-relevance/train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzljXWXRFTQg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.head()\n",
        "train['norm_relevance'] = (train['relevance'] - 1) / 2\n",
        "train.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kb-qaGVCa32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_product_title_len=train.product_title.map(lambda x: len(x)).max()\n",
        "max_search_term=train.search_term.map(lambda x: len(x)).max()\n",
        "max_input_len=max(max_product_title_len,max_search_term)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku4yaaZ0BmjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCharGenerator(Sequence):\n",
        "  def __init__(self,padding,df,batch_size=32,char_value=0):\n",
        "    self.padding=padding\n",
        "    self.char_value=char_value\n",
        "    self.df=df\n",
        "    self.batch_size=batch_size\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    while(True):\n",
        "      X1 = []\n",
        "      X2 = []\n",
        "      y = []\n",
        "\n",
        "      for index,row in self.df.iterrows():\n",
        "        y.append(row['norm_relevance'])\n",
        "        st_list= [ord(c) for c in list(row['search_term'])]\n",
        "        pt_list=[ord(c) for c in list(row['product_title'])]\n",
        "        #X1.append(np.pad(st_list,(0,self.padding-len(st_list))))\n",
        "        #X2.append(np.pad(pt_list,(0,self.padding-len(pt_list))))\n",
        "        X1.append(np.reshape(np.pad(st_list,(0,self.padding-len(st_list))),(147,1)))\n",
        "        X2.append(np.reshape(np.pad(pt_list,(0,self.padding-len(pt_list))),(147,1)))\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        if (index + 1) % self.batch_size == 0:\n",
        "          y=np.array(y)\n",
        "\n",
        "          yield (np.array([X1,X2]),y)\n",
        "          X1 = []\n",
        "          X2 = []\n",
        "          y=[]\n",
        "\n",
        "      y=np.array(y)\n",
        "      if(len(y) > 0):\n",
        "        yield np.array([X1,X2]),y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB5rXmhpzU-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyWordGenerator(Sequence):\n",
        "  def __init__(self,padding,df,batch_size=32,char_value=0):\n",
        "    self.padding=padding\n",
        "    self.char_value=char_value\n",
        "    self.df=df\n",
        "    self.batch_size=batch_size\n",
        "    self.words_dictonary = {}\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    while(True):\n",
        "      X1 = []\n",
        "      X2 = []\n",
        "      y = []\n",
        "\n",
        "      for index,row in self.df.iterrows():\n",
        "        y.append(row['norm_relevance'])\n",
        "        st_list = []\n",
        "        for word in row['search_term'].split(' '):\n",
        "          if not (word in self.words_dictonary):\n",
        "            self.words_dictonary[word] = len(self.words_dictonary)\n",
        "          st_list.append(self.words_dictonary[word])\n",
        "            \n",
        "        pt_list = []\n",
        "        for word in row['product_title'].split(' '):\n",
        "          if not (word in self.words_dictonary):\n",
        "            self.words_dictonary[word] = len(self.words_dictonary)\n",
        "          pt_list.append(self.words_dictonary[word])\n",
        "\n",
        "        X1.append(np.reshape(np.pad(st_list,(0,self.padding-len(st_list))),(self.padding,1)))\n",
        "        X2.append(np.reshape(np.pad(pt_list,(0,self.padding-len(pt_list))),(self.padding,1)))\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        if (index + 1) % self.batch_size == 0:\n",
        "          y=np.array(y)\n",
        "\n",
        "          yield (np.array([X1,X2]),y)\n",
        "          X1 = []\n",
        "          X2 = []\n",
        "          y=[]\n",
        "\n",
        "      y=np.array(y)\n",
        "      if(len(y) > 0):\n",
        "        yield np.array([X1,X2]),y\n",
        "\n",
        "loss_index = 0\n",
        "def rmse(y_true, y_pred):\n",
        "  return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def new_loss(y_actual,y_predicted):\n",
        "  global loss_index\n",
        "  global y_train\n",
        "  global X1_train\n",
        "  global X2_train\n",
        "\n",
        "  cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
        "  loss = tf.constant(0.0)\n",
        "  m = tf.constant(-0.00015)\n",
        "  x = tf.constant(0.0)\n",
        "  K.switch(tf.constant(y_train[x]))\n",
        "  for i in range(32):\n",
        "    if (True):\n",
        "      loss = tf.add(loss,tf.subtract(tf.constant(1.0),\n",
        "                                     cosine_loss(np.float32(X1_train[loss_index+i]),np.float32(X2_train[loss_index+i]))))\n",
        "    else:\n",
        "      loss = tf.add(loss,tf.maximum(tf.constant(0.0),\n",
        "                                    tf.subtract(cosine_loss(np.float32(X1_train[loss_index+i]), np.float32(X2_train[loss_index+i])),m)))\n",
        "  loss_index+=32\n",
        "  with open('log.log', 'a') as file:\n",
        "    json.dump(loss_index, file)\n",
        "  tf.Print(loss,[loss],(\"%s\" %loss_index))\n",
        "  #return tf.add(K.sum(tf.multiply(tf.constant(0.0),y_predicted)),loss)\n",
        "  return cosine_loss(y_actual,y_predicted)\n",
        "\n",
        "# siames_model=network(max_input_len)\n",
        "# siames_model.summary()\n",
        "# siames_model.compile(loss=new_loss ,optimizer='adam',metrics=['mae','accuracy'])\n",
        "# model_hist = siames_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=3,batch_size=32,validation_data=([X1_test,X2_test],y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmViaexjMFqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myGen=MyCharGenerator(padding=147,df=train,batch_size=1)\n",
        "it = iter(myGen)\n",
        "\n",
        "X1 = []\n",
        "X2 = []\n",
        "Y = []\n",
        "for time in range(len(train)):\n",
        "  [X1_gen,X2_gen],y_gen = next(it)\n",
        "  X1.append([X for X in X1_gen[0]])\n",
        "  X2.append([X for X in X2_gen[0]])\n",
        "  Y.append(y_gen[0])\n",
        "\n",
        "X1_train,X1_test,X2_train,X2_test,y_train,y_test = train_test_split(X1,X2,Y,test_size=0.2)\n",
        "\n",
        "X1_train = np.array(X1_train)\n",
        "X2_train = np.array(X2_train)\n",
        "y_train = np.array(y_train)\n",
        "X1_test = np.array(X1_test)\n",
        "X2_test = np.array(X2_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSunVdPWByqT",
        "colab_type": "code",
        "outputId": "2031217e-016a-4989-9804-d5b1cdbe9fd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "y_train*2+1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.33, 2.  , 2.  , ..., 2.  , 3.  , 1.  ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeiZtPowPSYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network(n_fetures,n_described=1):\n",
        "  inp=Input(shape=(n_fetures,n_described))\n",
        "  x = CuDNNLSTM(n_fetures)(inp)\n",
        "  x = Reshape((n_fetures,1))(x)\n",
        "  x=Conv1D(filters=32,kernel_size=10,activation='relu')(x)\n",
        "  x=MaxPool1D()(x)\n",
        "  x=Conv1D(filters=64,kernel_size=10,activation='relu')(x)\n",
        "  x=MaxPool1D()(x)\n",
        "  x=Conv1D(filters=128,kernel_size=10,activation='relu')(x)\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(128,activation='relu')(x)\n",
        "  model= Model(inp,x)\n",
        "\n",
        "  search_term_input=Input(shape=(n_fetures,n_described),name='inp1')\n",
        "  product_title_input=Input(shape=(n_fetures,n_described),name='inp2')\n",
        "\n",
        "  search_term_encoded=model(search_term_input)\n",
        "  product_title_encoded=model(product_title_input)\n",
        "\n",
        "\n",
        "  x_connected=Concatenate()([search_term_encoded,product_title_encoded])\n",
        "  x_connected=Dense(1,activation='sigmoid')(x_connected)\n",
        "  \n",
        "  \n",
        "  connected_model=Model(inputs=[search_term_input,product_title_input],output=x_connected)\n",
        "  connected_model.summary()\n",
        "\n",
        "  return connected_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UW61vXdshpw",
        "colab_type": "code",
        "outputId": "26159324-9a0b-4f1d-8be3-0065051210be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "siames_model=network(max_input_len)\n",
        "siames_model.summary()\n",
        "siames_model.compile(loss='msle' ,optimizer='adam',metrics=['mae','accuracy',rmse])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           model_3[1][0]                    \n",
            "                                                                 model_3[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            257         concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 535,593\n",
            "Trainable params: 535,593\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           model_3[1][0]                    \n",
            "                                                                 model_3[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1)            257         concatenate_2[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 535,593\n",
            "Trainable params: 535,593\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1J12Mt37hMd",
        "colab_type": "code",
        "outputId": "814e9b9d-d227-4d9d-d8bb-de17b9e490bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "model_hist = siames_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=1,batch_size=20,validation_data=([X1_test,X2_test],y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 59253 samples, validate on 14814 samples\n",
            "Epoch 1/1\n",
            " - 58s - loss: 0.0295 - mean_absolute_error: 0.2204 - acc: 0.2574 - rmse: 0.2204 - val_loss: 0.0299 - val_mean_absolute_error: 0.2223 - val_acc: 0.2614 - val_rmse: 0.2223\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x2RcIqjAXQP",
        "colab_type": "code",
        "outputId": "8e458cda-5550-45d4-b69f-dbd5356886b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "def get_query(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['query'].values\n",
        "def get_title(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['title'].values\n",
        "\n",
        "Naive_X = []\n",
        "Naive_Y = []\n",
        "\n",
        "for index,row in train.iterrows():\n",
        "  Naive_Y.append(row['relevance'])\n",
        "  Naive_X.append([''.join(list(row['search_term'])),''.join(list(row['product_title']))])\n",
        "\n",
        "X_naive_train,X_naive_test,y_naive_train,y_naive_test = train_test_split(Naive_X,Naive_Y,test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "     ('fetures',\n",
        "         FeatureUnion(\n",
        "             [\n",
        "                 ('later',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                          ('query',FunctionTransformer(get_query)),\n",
        "                          ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False,analyzer='char'))\n",
        "                      ]\n",
        "                  )),\n",
        "                 ('bins',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                       ('title',FunctionTransformer(get_title)),\n",
        "                       ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False,analyzer='char'))\n",
        "                      ]\n",
        "                  )\n",
        "                 )\n",
        "             ]\n",
        "         )\n",
        "      ),\n",
        "     ('clf', LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "naive_model = cross_validate(pipeline, X_naive_train, y_naive_train, cv=5,return_estimator=True)\n",
        "\n",
        "predictions = naive_model['estimator'][4].predict(X_naive_test)\n",
        "mae = np.absolute((np.array(y_naive_test)-np.array(predictions))).mean()\n",
        "\n",
        "\n",
        "\n",
        "print(mae2)\n",
        "\n",
        "rmse = math.sqrt(((np.array(y_naive_test)-np.array(predictions))**2).mean())\n",
        "print(\"MAE: %.3f\" %mae)\n",
        "print(\"RMSE: %.3f\" %rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5285226156942039\n",
            "MAE: 0.433\n",
            "RMSE: 0.529\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJkyvr0ndy-D",
        "colab_type": "code",
        "outputId": "387bf4eb-1caa-42b4-ea63-b51f4334cfdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "siames_model_ML = Model(siames_model.input,siames_model.layers[-2].output)\n",
        "siames_model_ML.compile(loss='mse',optimizer='SGD')\n",
        "siames_model_ML.summary()\n",
        "\n",
        "\n",
        "ml_predictions_train = siames_model_ML.predict([X1_train,X2_train])\n",
        "ml_predictions_test = siames_model_ML.predict([X1_test,X2_test])\n",
        "\n",
        "\n",
        "# siames_model_ML=network(max_input_len)\n",
        "# siames_model_ML.layers.pop(-1)\n",
        "# siames_model_ML.summary()\n",
        "# siames_model_ML.compile(optimizer='SGD',metrics=['mae','accuracy',rmse])\n",
        "# model_hist_ml = siames_model_ML.fit([X1_train,X2_train],y_train,verbose=2,epochs=10,batch_size=20,validation_data=([X1_test,X2_test],y_test))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_3 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 256)          0           model_3[1][0]                    \n",
            "                                                                 model_3[2][0]                    \n",
            "==================================================================================================\n",
            "Total params: 535,336\n",
            "Trainable params: 535,336\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "CPU times: user 17.5 s, sys: 680 ms, total: 18.2 s\n",
            "Wall time: 15.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqKhxc5p7R_C",
        "colab_type": "code",
        "outputId": "8e5b5e72-bbe2-43e2-bfdd-b1edcd385ef0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "ml_knn_model = KNeighborsRegressor(n_jobs=16,weights='distance',algorithm='kd_tree',n_neighbors=3)\n",
        "ml_knn_model.fit(ml_predictions_train,y_train*2+1)\n",
        "ml_knn_predictions = ml_knn_model.predict(ml_predictions_test)\n",
        "\n",
        "y_t=np.array(y_test)*2+1\n",
        "mae_knn = np.absolute((y_t-np.array(ml_knn_predictions))).mean()\n",
        "rmse_knn = math.sqrt(((y_t-np.array(ml_knn_predictions))**2).mean())\n",
        "\n",
        "print(\"KNN MAE: %.3f\" %mae_knn)\n",
        "print(\"KNN RMSE: %.3f\" %rmse_knn)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN MAE: 0.453\n",
            "KNN RMSE: 0.562\n",
            "CPU times: user 7min 33s, sys: 253 ms, total: 7min 33s\n",
            "Wall time: 3min 58s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no-lvCoQFysh",
        "colab_type": "code",
        "outputId": "baa998f5-8600-4f31-c76e-ee77d0aa5cc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "unique, counts = np.unique(ml_knn_predictions, return_counts=True)\n",
        "print (unique)\n",
        "print (counts)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         1.2639752  1.33       1.33850508 1.35683968 1.37684851\n",
            " 1.40170874 1.48551113 1.49318947 1.51520432 1.54528034 1.54840142\n",
            " 1.55333333 1.55370227 1.55666667 1.56102652 1.60391512 1.6523056\n",
            " 1.67       1.67135174 1.67300777 1.69752352 1.702356   1.70638421\n",
            " 1.724886   1.73299414 1.73308177 1.74927122 1.75835408 1.77189949\n",
            " 1.77203173 1.77548734 1.77666667 1.7779319  1.7862017  1.79708696\n",
            " 1.79872102 1.80698577 1.8221822  1.83       1.835      1.83604879\n",
            " 1.84003056 1.85911919 1.85946543 1.87558197 1.87636862 1.87811075\n",
            " 1.88586612 1.88666667 1.88666667 1.88735896 1.88961963 1.89\n",
            " 1.89       1.89       1.89       1.89122349 1.89527331 1.90210487\n",
            " 1.90525819 1.90691186 1.92208435 1.92410537 1.92479632 1.92484513\n",
            " 1.93293029 1.93595565 1.94136961 1.94541822 1.94838388 1.95267432\n",
            " 1.95377658 1.96413544 1.9663841  1.98372158 1.99021282 1.99884182\n",
            " 1.99979645 2.         2.00614939 2.00992365 2.01010851 2.01437976\n",
            " 2.01560123 2.02822784 2.0284162  2.03208716 2.03937769 2.03995145\n",
            " 2.04379097 2.0489104  2.06482048 2.07862273 2.08413859 2.0850773\n",
            " 2.08558701 2.08751238 2.09357726 2.09522167 2.09764701 2.10319413\n",
            " 2.10432272 2.10612815 2.10712534 2.10770695 2.1087031  2.10973611\n",
            " 2.10999093 2.11       2.11112301 2.11224745 2.11333333 2.11333333\n",
            " 2.11359099 2.11418317 2.11432461 2.11472309 2.12168315 2.12287742\n",
            " 2.12999108 2.13197149 2.13569264 2.13726445 2.14658285 2.15077792\n",
            " 2.1537826  2.16064119 2.16241773 2.16400937 2.165      2.16624935\n",
            " 2.1697239  2.17       2.17465963 2.17537914 2.17650308 2.18338958\n",
            " 2.18400864 2.18454692 2.19015238 2.19159401 2.19758734 2.19970501\n",
            " 2.20199932 2.20372022 2.20454386 2.20460766 2.20546062 2.20702578\n",
            " 2.20725601 2.20734147 2.21062898 2.21408831 2.21758459 2.21939812\n",
            " 2.22       2.22171987 2.22253044 2.22276026 2.22333333 2.22333333\n",
            " 2.22405615 2.22464375 2.22476335 2.22523525 2.23026272 2.23268151\n",
            " 2.23310243 2.23348266 2.2346533  2.24085146 2.24182015 2.24465846\n",
            " 2.24536768 2.24592586 2.24927321 2.25       2.25062438 2.25808638\n",
            " 2.26165942 2.26274252 2.2628407  2.26366358 2.27116445 2.27460929\n",
            " 2.2746172  2.2758467  2.27645176 2.2804398  2.28630345 2.28712545\n",
            " 2.28733037 2.28909374 2.29155042 2.29338343 2.29341973 2.30014526\n",
            " 2.30102772 2.30222144 2.30292454 2.30425439 2.30871392 2.30872279\n",
            " 2.31323678 2.31562853 2.32121726 2.32242079 2.32457654 2.32561359\n",
            " 2.32653735 2.32856665 2.33       2.33       2.33111807 2.33113403\n",
            " 2.3315041  2.33277085 2.33277995 2.33333333 2.335      2.33548286\n",
            " 2.33579642 2.33666667 2.33742888 2.3376295  2.3433738  2.3471508\n",
            " 2.34904089 2.34942438 2.35093443 2.35126447 2.35361213 2.35657339\n",
            " 2.36210769 2.36339763 2.36490019 2.36917204 2.37305723 2.37383477\n",
            " 2.37680318 2.38271883 2.38705171 2.38953113 2.39088965 2.3938466\n",
            " 2.3943329  2.39782631 2.39996089 2.40126678 2.40180889 2.40368594\n",
            " 2.40407276 2.40486226 2.40569613 2.40603955 2.40904491 2.41018862\n",
            " 2.41426708 2.4172032  2.4225669  2.42311834 2.42868178 2.42967397\n",
            " 2.43114905 2.4314117  2.43211344 2.43211469 2.43224418 2.43269204\n",
            " 2.43879409 2.4409007  2.44333333 2.44333333 2.44333333 2.4440128\n",
            " 2.44436427 2.44443488 2.44666667 2.44666667 2.4473709  2.44804152\n",
            " 2.44806344 2.44830404 2.4485077  2.44952245 2.44961866 2.45219001\n",
            " 2.45344954 2.4555229  2.46026596 2.46054254 2.46250739 2.46286873\n",
            " 2.46331696 2.46503629 2.4655933  2.46761285 2.47061817 2.47291827\n",
            " 2.47359659 2.47430521 2.47632141 2.47888415 2.48082068 2.48135426\n",
            " 2.48320586 2.48479096 2.48513705 2.48875398 2.49040365 2.49384701\n",
            " 2.49582887 2.49657041 2.5        2.50668449 2.50796876 2.50810989\n",
            " 2.5109227  2.51147933 2.51249864 2.51697046 2.51801934 2.51851378\n",
            " 2.52401291 2.52817028 2.535162   2.53685623 2.54014688 2.54397676\n",
            " 2.54415451 2.54739603 2.54848485 2.55046828 2.55133475 2.55169314\n",
            " 2.55287442 2.55549045 2.55666667 2.55666667 2.55688869 2.56154724\n",
            " 2.56271131 2.56541651 2.56596444 2.57299989 2.57357152 2.57511383\n",
            " 2.57549169 2.57566358 2.57655632 2.58574635 2.58690572 2.58867053\n",
            " 2.58900015 2.59146835 2.5920608  2.5933441  2.5952642  2.59731374\n",
            " 2.60728767 2.60964826 2.61337436 2.61736451 2.62050569 2.62538973\n",
            " 2.62950042 2.63677312 2.63697145 2.63954669 2.64277078 2.64350487\n",
            " 2.6446754  2.64868404 2.64935823 2.65123732 2.65660976 2.65829102\n",
            " 2.6626249  2.66364984 2.665      2.66533262 2.6656622  2.6658607\n",
            " 2.66650155 2.66652688 2.66654301 2.66654711 2.66666667 2.66666667\n",
            " 2.66667326 2.66720513 2.66802727 2.67       2.67       2.67551837\n",
            " 2.6765157  2.68239906 2.68529899 2.6905417  2.69322552 2.69490159\n",
            " 2.69599897 2.69749074 2.69810224 2.70103964 2.71776442 2.71967611\n",
            " 2.72842347 2.72860453 2.74682335 2.74739041 2.74824336 2.74854046\n",
            " 2.75258767 2.75446142 2.76718918 2.7712528  2.77625636 2.77666667\n",
            " 2.78       2.78061522 2.78074866 2.78465309 2.78566493 2.78663055\n",
            " 2.78767403 2.78928141 2.79268808 2.79760267 2.79823708 2.8005572\n",
            " 2.80071877 2.80204884 2.80286325 2.80924391 2.81025152 2.81782573\n",
            " 2.82288843 2.835      2.83808164 2.83891516 2.84315696 2.84866391\n",
            " 2.84967127 2.85952403 2.8674249  2.8682822  2.87127293 2.87547783\n",
            " 2.88498872 2.88801058 2.88953963 2.88967707 2.89       2.89223273\n",
            " 2.89321636 2.91268705 2.91315327 2.93315098 2.94238438 2.96567852\n",
            " 2.97962173 3.         3.         3.        ]\n",
            "[    4     1    10     1     1     2     1     1     1     1     1     1\n",
            "     1     1     3     1     1     1    13     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     3     1     1     1\n",
            "     1     1     1     1     3     1     1     1     1     1     1     1\n",
            "     1     1     3     1     1     2     2     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1    40     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     2\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     4     1     1     1     2     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     5     1\n",
            "     1     3     1     1     1     1     1     1     1     1     1     1\n",
            "     2     1     1     1     1     1     1     1     1     1     1     1\n",
            "     2     1     2     1     2     2     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     2\n",
            "     2     1     1     1     1     1     1     1     1    55     1     1\n",
            "     1     1     1    12     4     1     1     2     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     2     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1    11     1     1\n",
            "     1     1     1     6     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     2     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     9     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1 14056     3     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     2     1     1     1     1     1     1     6     1     1     1\n",
            "     1     1     1     1     9     1     1     1     1     2    40     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     2\n",
            "     2     1     1     1     1     1     1     1     1     2     1     2\n",
            "     1     1     1     1     1     1     1     1     1     1     2     1\n",
            "     1     1     1     1     1     1     1     8     1     1     1     1\n",
            "     2     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     2     1    38     1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_xPOgCx7zx7",
        "colab_type": "code",
        "outputId": "17bdd334-2fa5-4984-957f-15e74c9789e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "ml_rf_model = RandomForestRegressor(n_jobs=8,min_samples_leaf=3)\n",
        "ml_rf_model.fit(ml_predictions_train,y_train*2+1)\n",
        "ml_rf_predictions = ml_rf_model.predict(ml_predictions_test)\n",
        "\n",
        "y_t_rf=y_test*2+1\n",
        "\n",
        "mae_rf = np.absolute((np.array(y_t_rf)-np.array(ml_rf_predictions))).mean()\n",
        "rmse_rf = math.sqrt(((np.array(y_t_rf)-np.array(ml_rf_predictions))**2).mean())\n",
        "\n",
        "\n",
        "print(\"RANDOM MAE: %.3f\" %mae_rf)\n",
        "print(\"RANDOM RMSE: %.3f\" %rmse_rf)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-4f4ed9722dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\nml_rf_model = RandomForestRegressor(n_jobs=8,min_samples_leaf=3,criterion=\\'mae\\')\\nml_rf_model.fit(ml_predictions_train,y_train*2+1)\\nml_rf_predictions = ml_rf_model.predict(ml_predictions_test)\\n\\ny_t_rf=y_test*2+1\\n\\nmae_rf = np.absolute((np.array(y_t_rf)-np.array(ml_rf_predictions))).mean()\\nrmse_rf = math.sqrt(((np.array(y_t_rf)-np.array(ml_rf_predictions))**2).mean())\\n\\n\\nprint(\"RANDOM MAE: %.3f\" %mae_rf)\\nprint(\"RANDOM RMSE: %.3f\" %rmse_rf)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    381\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 383\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH7hO98KaTqr",
        "colab_type": "text"
      },
      "source": [
        "We explored the data and decided we need to do some preprocessing\n",
        "\n",
        "we found some examples for words that ment the same thing but were wrote differently.\n",
        "\n",
        "for example in the 'product title' column there is no 'inches' there is 'in.'\n",
        "but in the 'search term' there is 'inches'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s1DYXGkZDFZ",
        "colab_type": "code",
        "outputId": "b7ba975b-dd8c-4243-a282-ed5a39b9df46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        " print ('\\'product_titles\\' contains \\'inches\\'')\n",
        " display(train.loc[train['product_title'].str.contains(' inches ')])\n",
        " print ('\\n\\n\\n\\'search_terms\\' contains \\'inches\\'')\n",
        " display(train.loc[train['search_term'].str.contains(' inches ')].head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'product_titles' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, product_uid, product_title, search_term, relevance, norm_relevance]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "'search_terms' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>12507</td>\n",
              "      <td>102193</td>\n",
              "      <td>Samsung 28.15 cu. ft. 4-Door French Door Refri...</td>\n",
              "      <td>33 inches wide samsung</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13646</th>\n",
              "      <td>42206</td>\n",
              "      <td>110179</td>\n",
              "      <td>JELD-WEN Smooth 4-Panel Primed Molded Interior...</td>\n",
              "      <td>interior doors 82 inches in length</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14917</th>\n",
              "      <td>46069</td>\n",
              "      <td>111389</td>\n",
              "      <td>Paslode 3 in. x 0.131-Gauge 30å¡ Brite Smooth ...</td>\n",
              "      <td>3 .5 inches paper tape collated</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15609</th>\n",
              "      <td>48121</td>\n",
              "      <td>112069</td>\n",
              "      <td>Roberts Laminate Cutter for Cross Cutting up t...</td>\n",
              "      <td>metric to inches converter</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17099</th>\n",
              "      <td>52792</td>\n",
              "      <td>113648</td>\n",
              "      <td>Masonite 30 in. x 80 in. Textured 6-Panel Holl...</td>\n",
              "      <td>interior doors 82 inches in length</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... relevance norm_relevance\n",
              "4015   12507       102193  ...      2.67          0.835\n",
              "13646  42206       110179  ...      2.33          0.665\n",
              "14917  46069       111389  ...      2.00          0.500\n",
              "15609  48121       112069  ...      1.67          0.335\n",
              "17099  52792       113648  ...      2.67          0.835\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0-tgTBOiUBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def preprocess_sentences(s):\n",
        "  s = s.lower()\n",
        "  s = re.sub(r\"(\\d+)'\",r'\\1in.',s)\n",
        "  s = s.replace(\"inches\",\"in.\") \n",
        "  s = s.replace(\"inch\",\"in.\")\n",
        "  s = s.replace(\" in \",\"in. \") \n",
        "  s = s.replace(\" in.\",\"in.\") \n",
        "\n",
        "  s = s.replace(\"''\",\"ft.\") \n",
        "  s = s.replace(\" feet \",\"ft. \") \n",
        "  s = s.replace(\"feet\",\"ft.\") \n",
        "  s = s.replace(\"foot\",\"ft.\") \n",
        "  s = s.replace(\" ft \",\"ft. \") \n",
        "  s = s.replace(\" ft.\",\"ft.\") \n",
        "\n",
        "  s = s.replace(\" pounds \",\"lb. \")\n",
        "  s = s.replace(\" pound \",\"lb. \") \n",
        "  s = s.replace(\"pound\",\"lb.\") \n",
        "  s = s.replace(\" lb \",\"lb. \") \n",
        "  s = s.replace(\" lb.\",\"lb.\") \n",
        "  s = s.replace(\" lbs \",\"lb. \") \n",
        "  s = s.replace(\"lbs.\",\"lb.\") \n",
        "\n",
        "  s = s.replace(\" x \",\" xby \")\n",
        "  s = s.replace(\"*\",\" xby \")\n",
        "  s = s.replace(\" by \",\" xby\")\n",
        "  s = s.replace(\"x0\",\" xby 0\")\n",
        "  s = s.replace(\"x1\",\" xby 1\")\n",
        "  s = s.replace(\"x2\",\" xby 2\")\n",
        "  s = s.replace(\"x3\",\" xby 3\")\n",
        "  s = s.replace(\"x4\",\" xby 4\")\n",
        "  s = s.replace(\"x5\",\" xby 5\")\n",
        "  s = s.replace(\"x6\",\" xby 6\")\n",
        "  s = s.replace(\"x7\",\" xby 7\")\n",
        "  s = s.replace(\"x8\",\" xby 8\")\n",
        "  s = s.replace(\"x9\",\" xby 9\")\n",
        "  s = s.replace(\"0x\",\"0 xby \")\n",
        "  s = s.replace(\"1x\",\"1 xby \")\n",
        "  s = s.replace(\"2x\",\"2 xby \")\n",
        "  s = s.replace(\"3x\",\"3 xby \")\n",
        "  s = s.replace(\"4x\",\"4 xby \")\n",
        "  s = s.replace(\"5x\",\"5 xby \")\n",
        "  s = s.replace(\"6x\",\"6 xby \")\n",
        "  s = s.replace(\"7x\",\"7 xby \")\n",
        "  s = s.replace(\"8x\",\"8 xby \")\n",
        "  s = s.replace(\"9x\",\"9 xby \")\n",
        "\n",
        "  s = s.replace(\" sq ft\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq ft\",\"sq.ft. \")\n",
        "  s = s.replace(\"sqft\",\"sq.ft. \")\n",
        "  s = s.replace(\" sqft \",\"sq.ft. \") \n",
        "  s = s.replace(\"sq. ft\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq ft.\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq feet\",\"sq.ft. \") \n",
        "  s = s.replace(\"square feet\",\"sq.ft. \") \n",
        "\n",
        "  s = s.replace(\" gallons \",\"gal. \") \n",
        "  s = s.replace(\" gallon \",\"gal. \") \n",
        "  s = s.replace(\"gallons\",\"gal.\") \n",
        "  s = s.replace(\"gallon\",\"gal.\") \n",
        "  s = s.replace(\" gal \",\"gal. \") \n",
        "  s = s.replace(\" gal\",\"gal.\") \n",
        "\n",
        "  s = s.replace(\"ounces\",\"oz.\")\n",
        "  s = s.replace(\"ounce\",\"oz.\")\n",
        "  s = s.replace(\" oz.\",\"oz. \")\n",
        "  s = s.replace(\" oz \",\"oz. \")\n",
        "\n",
        "  s = s.replace(\"centimeters\",\"cm.\")    \n",
        "  s = s.replace(\" cm.\",\"cm.\")\n",
        "  s = s.replace(\" cm \",\"cm. \")\n",
        "  \n",
        "  s = s.replace(\"milimeters\",\"mm.\")\n",
        "  s = s.replace(\" mm.\",\"mm.\")\n",
        "  s = s.replace(\" mm \",\"mm. \")\n",
        "  \n",
        "  s = s.replace(\"°\",\"deg. \")\n",
        "  s = s.replace(\"degrees\",\"deg. \")\n",
        "  s = s.replace(\"degree\",\"deg. \")\n",
        "  \n",
        "  s = s.replace(\"volts\",\"volt. \")\n",
        "  s = s.replace(\"volt\",\"volt. \")\n",
        "\n",
        "  s = s.replace(\"watts\",\"watt. \")\n",
        "  s = s.replace(\"watt\",\"watt. \")\n",
        "\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwU0AA9eooKS",
        "colab_type": "code",
        "outputId": "6a1922fe-46cd-468d-b5f5-8cdd6e2e168e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "processed_train = train.copy()\n",
        "processed_train['search_term'] = processed_train['search_term'].map(lambda x:preprocess_sentences(x))\n",
        "processed_train['product_title'] = processed_train['product_title'].map(lambda x:preprocess_sentences(x))\n",
        "\n",
        "print ('\\'product_titles\\' contains \\'inches\\'')\n",
        "display(processed_train.loc[processed_train['product_title'].str.contains(' in. ')])\n",
        "print ('\\n\\n\\n\\'search_terms\\' contains \\'inches\\'')\n",
        "display(processed_train.loc[processed_train['search_term'].str.contains(' in. ')].head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'product_titles' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18498</th>\n",
              "      <td>57112</td>\n",
              "      <td>115108</td>\n",
              "      <td>ready-strip 32oz.  environmentally friendly dr...</td>\n",
              "      <td>adhesive slide strip</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25119</th>\n",
              "      <td>77115</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>12in. ceiling tile</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25120</th>\n",
              "      <td>77121</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>sound dampening</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25121</th>\n",
              "      <td>77123</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>sounds panels</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67581</th>\n",
              "      <td>202995</td>\n",
              "      <td>191353</td>\n",
              "      <td>mohawk home ink swirl cocoa 2ft. xby 8ft. runner</td>\n",
              "      <td>rug ruunners</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ... relevance norm_relevance\n",
              "18498   57112       115108  ...      1.67          0.335\n",
              "25119   77115       122211  ...      2.00          0.500\n",
              "25120   77121       122211  ...      2.67          0.835\n",
              "25121   77123       122211  ...      2.00          0.500\n",
              "67581  202995       191353  ...      2.00          0.500\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "'search_terms' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42161</th>\n",
              "      <td>128340</td>\n",
              "      <td>144629</td>\n",
              "      <td>liberty 20in. european self-closing drawer sli...</td>\n",
              "      <td>18.75 in. drawer slides</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54368</th>\n",
              "      <td>164835</td>\n",
              "      <td>164764</td>\n",
              "      <td>kaleen matira blue 2ft. xby 3ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55418</th>\n",
              "      <td>167918</td>\n",
              "      <td>166665</td>\n",
              "      <td>kaleen matira blue 2ft. xby 3ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60397</th>\n",
              "      <td>182300</td>\n",
              "      <td>176124</td>\n",
              "      <td>kaleen matira blue 3ft. xby 5ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ... relevance norm_relevance\n",
              "42161  128340       144629  ...      2.67          0.835\n",
              "54368  164835       164764  ...      2.00          0.500\n",
              "55418  167918       166665  ...      3.00          1.000\n",
              "60397  182300       176124  ...      3.00          1.000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxC6_oHYqgFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_product_title_len=processed_train.product_title.map(lambda x: len(x.split(' '))).max()\n",
        "max_search_term=processed_train.search_term.map(lambda x: len(x.split(' '))).max()\n",
        "max_input_len=max(max_product_title_len,max_search_term,70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHoxrjE4AAxO",
        "colab_type": "code",
        "outputId": "98cb133f-0beb-49bb-869f-c6bb37cd3faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "myGen=MyWordGenerator(padding=max_input_len,df=processed_train,batch_size=1)\n",
        "it = iter(myGen)\n",
        "\n",
        "X1 = []\n",
        "X2 = []\n",
        "Y = []\n",
        "for time in range(len(processed_train)):\n",
        "  [X1_gen,X2_gen],y_gen = next(it)\n",
        "  X1.append([X for X in X1_gen[0]])\n",
        "  X2.append([X for X in X2_gen[0]])\n",
        "  Y.append(y_gen[0])\n",
        "\n",
        "X1_train,X1_test,X2_train,X2_test,y_train,y_test = train_test_split(X1,X2,Y,test_size=0.2)\n",
        "\n",
        "X1_train = np.array(X1_train)\n",
        "X2_train = np.array(X2_train)\n",
        "y_train = np.array(y_train)\n",
        "X1_test = np.array(X1_test)\n",
        "X2_test = np.array(X2_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-4024bfbb62c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;34m[\u001b[0m\u001b[0mX1_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX1_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX2_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-c1b9575c9784>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m           \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks8aV-82vmUc",
        "colab_type": "code",
        "outputId": "bb06d447-2224-48d6-fea4-42c7c019d938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "source": [
        "def embedding_input(name, n_in, n_out, reg=1e-4):\n",
        "    inp = Input(shape=(70,1), dtype='int64', name=name)\n",
        "    x = Flatten()(inp)\n",
        "    return inp, Embedding(n_in, n_out, input_length=70, embeddings_regularizer=l2(reg))(x)\n",
        "\n",
        "query_inp,query_emb = embedding_input(\"query\",len(processed_train.search_term.unique()),50)\n",
        "title_inp,title_emb = embedding_input(\"title\",len(processed_train.product_title.unique()),50)\n",
        "x = Concatenate()([query_emb,title_emb])\n",
        "x = Flatten()(x)\n",
        "x = Dense(1,activation='relu')(x)\n",
        "embedding_model = Model([query_inp, title_inp], x)\n",
        "embedding_model.compile(optimizer='adam', loss='msle',metrics=['accuracy',rmse,'mae'])\n",
        "embedding_model.summary()\n",
        "\n",
        "embedding_model_hist = embedding_model.fit([X1_train,X2_train], y_train, batch_size=64, epochs=3, \n",
        "          validation_data=([X1_test,X2_test], y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "query (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "title (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 70)           0           query[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 70)           0           title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 70, 50)       589450      flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 50)       2673650     flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 70, 100)      0           embedding_3[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 7000)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            7001        flatten_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,270,101\n",
            "Trainable params: 3,270,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-1fa42c4c032d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m embedding_model_hist = embedding_model.fit([X1_train,X2_train], y_train, batch_size=64, epochs=3, \n\u001b[0;32m---> 16\u001b[0;31m           validation_data=([X1_test,X2_test], y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected query to have shape (70, 1) but got array with shape (147, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmaWxLgVDWUU",
        "colab_type": "code",
        "outputId": "9c7bf060-e60b-46a5-8173-bdfcedd9d708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "inp=Input(shape=(70,50))\n",
        "x = CuDNNLSTM(70)(inp)\n",
        "x = Reshape((70,1))(x)\n",
        "x=Conv1D(filters=32,kernel_size=10,activation='relu')(x)\n",
        "x=MaxPool1D()(x)\n",
        "x=Conv1D(filters=64,kernel_size=10,activation='relu')(x)\n",
        "x=MaxPool1D()(x)\n",
        "x=Conv1D(filters=128,kernel_size=10,activation='relu')(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "model= Model(inp,x)\n",
        "\n",
        "search_term_encoded=model(query_emb)\n",
        "product_title_encoded=model(title_emb)\n",
        "\n",
        "\n",
        "x_connected=Concatenate()([search_term_encoded,product_title_encoded])\n",
        "x_connected=Dense(1,activation='sigmoid')(x_connected)\n",
        "\n",
        "siames_embedded_model = Model([query_inp,title_inp],x_connected)\n",
        "siames_embedded_model.summary()\n",
        "siames_embedded_model.compile(loss='mse' ,optimizer='adam',metrics=['mae','accuracy',rmse])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_172\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "query (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "title (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_32 (Flatten)            (None, 70)           0           query[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_33 (Flatten)            (None, 70)           0           title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 70, 50)       589450      flatten_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 50)       2673650     flatten_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "model_171 (Model)               (None, 128)          153616      embedding_3[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 256)          0           model_171[1][0]                  \n",
            "                                                                 model_171[2][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_135 (Dense)               (None, 1)            257         concatenate_67[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 3,416,973\n",
            "Trainable params: 3,416,973\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUxb3proDeoy",
        "colab_type": "code",
        "outputId": "4e92bf3a-e342-4a83-91ca-4d35d37b9428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "word_model_hist = siames_embedded_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=3,batch_size=32,validation_data=([X1_test,X2_test],y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 59253 samples, validate on 14814 samples\n",
            "Epoch 1/3\n",
            " - 46s - loss: 0.0720 - mean_absolute_error: 0.2197 - acc: 0.2582 - rmse: 0.2197 - val_loss: 0.0709 - val_mean_absolute_error: 0.2185 - val_acc: 0.2578 - val_rmse: 0.2185\n",
            "Epoch 2/3\n",
            " - 33s - loss: 0.0715 - mean_absolute_error: 0.2190 - acc: 0.2583 - rmse: 0.2190 - val_loss: 0.0717 - val_mean_absolute_error: 0.2209 - val_acc: 0.2578 - val_rmse: 0.2209\n",
            "Epoch 3/3\n",
            " - 34s - loss: 0.0715 - mean_absolute_error: 0.2191 - acc: 0.2583 - rmse: 0.2191 - val_loss: 0.0709 - val_mean_absolute_error: 0.2189 - val_acc: 0.2578 - val_rmse: 0.2189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38OlCiMwDr42",
        "colab_type": "code",
        "outputId": "cb050659-0298-4a27-b1fb-4bbe4bd9074b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_query(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['query'].values\n",
        "def get_title(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['title'].values\n",
        "\n",
        "Naive_X = []\n",
        "Naive_Y = []\n",
        "for index,row in processed_train.iterrows():\n",
        "  Naive_Y.append(row['relevance'])\n",
        "  Naive_X.append([row['search_term'],row['product_title']])\n",
        "\n",
        "X_naive_train,X_naive_test,y_naive_train,y_naive_test = train_test_split(Naive_X,Naive_Y,test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "     ('fetures',\n",
        "         FeatureUnion(\n",
        "             [\n",
        "                 ('later',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                          ('query',FunctionTransformer(get_query)),\n",
        "                          ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False))\n",
        "                      ]\n",
        "                  )),\n",
        "                 ('bins',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                       ('title',FunctionTransformer(get_title)),\n",
        "                       ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False))\n",
        "                      ]\n",
        "                  )\n",
        "                 )\n",
        "             ]\n",
        "         )\n",
        "      ),\n",
        "     ('clf', LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "naive_word_model = cross_validate(pipeline, X_naive_train ,y_naive_train, cv=3,return_estimator=True)\n",
        "\n",
        "predictions = naive_word_model['estimator'][2].predict(X_naive_test)\n",
        "mae = np.absolute((np.array(y_naive_test)-np.array(predictions))).mean()\n",
        "rmse = math.sqrt(((np.array(y_naive_test)-np.array(predictions))**2).mean())\n",
        "print(\"MAE: %.3f\" %mae)\n",
        "print(\"RMSE: %.3f\" %rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.427\n",
            "RMSE: 0.538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3xSbRkPDxE8",
        "colab_type": "code",
        "outputId": "d63bf98b-4170-4065-bd3e-41b27f4fef61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        }
      },
      "source": [
        "\n",
        "siames_word_model_ML = Model(siames_embedded_model.input,siames_embedded_model.layers[-2].output)\n",
        "siames_word_model_ML.compile(optimizer='SGD')\n",
        "siames_word_model_ML.summary()\n",
        "\n",
        "\n",
        "word_ml_predictions_train = siames_word_model_ML.predict([X1_train,X2_train])\n",
        "word_ml_predictions_test = siames_word_model_ML.predict([X1_test,X2_test])\n",
        "\n",
        "ml_knn_word_model = KNeighborsRegressor()\n",
        "ml_knn_word_model.fit(word_ml_predictions_train,y_train)\n",
        "word_ml_knn_predictions = ml_knn_word_model.predict(word_ml_predictions_test)\n",
        "\n",
        "ml_rf_word_model = RandomForestRegressor()\n",
        "ml_rf_word_model.fit(word_ml_predictions_train,y_train)\n",
        "word_ml_rf_predictions = ml_rf_word_model.predict(word_ml_predictions_test)\n",
        "\n",
        "\n",
        "word_mae_knn = np.absolute((np.array(y_naive_test)-np.array(word_ml_knn_predictions))).mean()\n",
        "word_rmse_knn = math.sqrt(((np.array(y_naive_test)-np.array(word_ml_knn_predictions))**2).mean())\n",
        "\n",
        "word_mae_rf = np.absolute((np.array(y_naive_test)-np.array(word_ml_rf_predictions))).mean()\n",
        "word_rmse_rf = math.sqrt(((np.array(y_naive_test)-np.array(word_ml_rf_predictions))**2).mean())\n",
        "\n",
        "print(\"KNN MAE: %.3f\" %word_mae_knn)\n",
        "print(\"KNN RMSE: %.3f\" %word_rmse_knn)\n",
        "\n",
        "print(\"RANDOM MAE: %.3f\" %word_mae_rf)\n",
        "print(\"RANDOM RMSE: %.3f\" %word_rmse_rf)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_170\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "query (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "title (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_32 (Flatten)            (None, 70)           0           query[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_33 (Flatten)            (None, 70)           0           title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 70, 50)       589450      flatten_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 50)       2673650     flatten_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "model_166 (Model)               (None, 128)          153616      embedding_3[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_66 (Concatenate)    (None, 256)          0           model_166[1][0]                  \n",
            "                                                                 model_166[2][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,416,716\n",
            "Trainable params: 3,416,716\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-146-639b363e475b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mword_mae_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_naive_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ml_knn_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mword_rmse_knn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_naive_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_ml_knn_predictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_naive_test' is not defined"
          ]
        }
      ]
    }
  ]
}