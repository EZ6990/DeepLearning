{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KaggleHomeDepot.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EZ6990/DeepLearning/blob/master/KaggleHomeDepot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcWETgmj4eMF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir .kaggle\n",
        "import json\n",
        "token = {\"username\":\"bgudltaldanny\",\"key\":\"65b62f1a36c14c834b4e88037463a4f8\"}\n",
        "with open('.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ1YdBKItNir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !cp .kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!touch ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofdMM5XJveEJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp .kaggle/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKXPhN_vv3hJ",
        "colab_type": "code",
        "outputId": "16ced131-b9dd-4bea-a77e-4da765479300",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        }
      },
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!pip uninstall -y kaggle\n",
        "!pip install --upgrade pip\n",
        "!pip install kaggle==1.5.6\n",
        "\n",
        "\n",
        "!kaggle competitions download -c home-depot-product-search-relevance\n",
        "!unzip home-depot-product-search-relevance.zip -d home-depot-product-search-relevance/\n",
        "!unzip home-depot-product-search-relevance/train.csv.zip -d home-depot-product-search-relevance/\n",
        "!unzip home-depot-product-search-relevance/test.csv.zip -d home-depot-product-search-relevance/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: kaggle 1.5.6\n",
            "Uninstalling kaggle-1.5.6:\n",
            "  Successfully uninstalled kaggle-1.5.6\n",
            "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
            "Processing /root/.cache/pip/wheels/01/3e/ff/77407ebac3ef71a79b9166a8382aecf88415a0bcbe3c095a01/kaggle-1.5.6-py3-none-any.whl\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2019.11.28)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (2.21.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.12.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle==1.5.6) (4.28.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle==1.5.6) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle==1.5.6) (1.3)\n",
            "Installing collected packages: kaggle\n",
            "Successfully installed kaggle-1.5.6\n",
            "Downloading home-depot-product-search-relevance.zip to /content\n",
            " 94% 65.0M/69.4M [00:00<00:00, 83.2MB/s]\n",
            "100% 69.4M/69.4M [00:00<00:00, 137MB/s] \n",
            "Archive:  home-depot-product-search-relevance.zip\n",
            "  inflating: home-depot-product-search-relevance/attributes.csv.zip  \n",
            "  inflating: home-depot-product-search-relevance/product_descriptions.csv.zip  \n",
            "  inflating: home-depot-product-search-relevance/relevance_instructions.docx  \n",
            "  inflating: home-depot-product-search-relevance/sample_submission.csv.zip  \n",
            "  inflating: home-depot-product-search-relevance/test.csv.zip  \n",
            "  inflating: home-depot-product-search-relevance/train.csv.zip  \n",
            "Archive:  home-depot-product-search-relevance/train.csv.zip\n",
            "  inflating: home-depot-product-search-relevance/train.csv  \n",
            "Archive:  home-depot-product-search-relevance/test.csv.zip\n",
            "  inflating: home-depot-product-search-relevance/test.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r10iXLp-DFP",
        "colab_type": "code",
        "outputId": "ffdf6f96-0460-4ac3-87ab-bf521c03f2e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "from keras.utils import Sequence\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout,Conv1D, MaxPool1D,Concatenate, LSTM, Reshape, CuDNNLSTM, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "import keras.backend as K\n",
        "from sklearn.pipeline import Pipeline,FeatureUnion,make_pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer,KBinsDiscretizer,OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score,cross_val_predict,cross_validate\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer,TfidfTransformer\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from keras.regularizers import l2\n",
        "from scipy import spatial\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaItXIaqBPac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='./home-depot-product-search-relevance'\n",
        "train=pd.read_csv(path+'/train.csv',encoding=\"Latin-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzljXWXRFTQg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "8b702fba-a722-44d9-9ba9-9ce2d577dd8b"
      },
      "source": [
        "train.head()\n",
        "train['norm_relevance'] = (train['relevance'] - 1) / 2\n",
        "train.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>100001</td>\n",
              "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
              "      <td>angle bracket</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>100001</td>\n",
              "      <td>Simpson Strong-Tie 12-Gauge Angle</td>\n",
              "      <td>l bracket</td>\n",
              "      <td>2.50</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>100002</td>\n",
              "      <td>BEHR Premium Textured DeckOver 1-gal. #SC-141 ...</td>\n",
              "      <td>deck over</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16</td>\n",
              "      <td>100005</td>\n",
              "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
              "      <td>rain shower head</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>17</td>\n",
              "      <td>100005</td>\n",
              "      <td>Delta Vero 1-Handle Shower Only Faucet Trim Ki...</td>\n",
              "      <td>shower only faucet</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  product_uid  ... relevance norm_relevance\n",
              "0   2       100001  ...      3.00          1.000\n",
              "1   3       100001  ...      2.50          0.750\n",
              "2   9       100002  ...      3.00          1.000\n",
              "3  16       100005  ...      2.33          0.665\n",
              "4  17       100005  ...      2.67          0.835\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kb-qaGVCa32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_product_title_len=train.product_title.map(lambda x: len(x)).max()\n",
        "max_search_term=train.search_term.map(lambda x: len(x)).max()\n",
        "max_input_len=max(max_product_title_len,max_search_term)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ku4yaaZ0BmjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyCharGenerator(Sequence):\n",
        "  def __init__(self,padding,df,batch_size=32,char_value=0):\n",
        "    self.padding=padding\n",
        "    self.char_value=char_value\n",
        "    self.df=df\n",
        "    self.batch_size=batch_size\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    while(True):\n",
        "      X1 = []\n",
        "      X2 = []\n",
        "      y = []\n",
        "\n",
        "      for index,row in self.df.iterrows():\n",
        "        y.append(row['norm_relevance'])\n",
        "        st_list= [ord(c) for c in list(row['search_term'])]\n",
        "        pt_list=[ord(c) for c in list(row['product_title'])]\n",
        "        #X1.append(np.pad(st_list,(0,self.padding-len(st_list))))\n",
        "        #X2.append(np.pad(pt_list,(0,self.padding-len(pt_list))))\n",
        "        X1.append(np.reshape(np.pad(st_list,(0,self.padding-len(st_list))),(147,1)))\n",
        "        X2.append(np.reshape(np.pad(pt_list,(0,self.padding-len(pt_list))),(147,1)))\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        if (index + 1) % self.batch_size == 0:\n",
        "          y=np.array(y)\n",
        "\n",
        "          yield (np.array([X1,X2]),y)\n",
        "          X1 = []\n",
        "          X2 = []\n",
        "          y=[]\n",
        "\n",
        "      y=np.array(y)\n",
        "      if(len(y) > 0):\n",
        "        yield np.array([X1,X2]),y\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB5rXmhpzU-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyWordGenerator(Sequence):\n",
        "  def __init__(self,padding,df,batch_size=32,char_value=0):\n",
        "    self.padding=padding\n",
        "    self.char_value=char_value\n",
        "    self.df=df\n",
        "    self.batch_size=batch_size\n",
        "    self.words_dictonary = {}\n",
        "\n",
        "\n",
        "  def __iter__(self):\n",
        "    while(True):\n",
        "      X1 = []\n",
        "      X2 = []\n",
        "      y = []\n",
        "\n",
        "      for index,row in self.df.iterrows():\n",
        "        y.append(row['norm_relevance'])\n",
        "        st_list = []\n",
        "        for word in row['search_term'].split(' '):\n",
        "          if not (word in self.words_dictonary):\n",
        "            self.words_dictonary[word] = len(self.words_dictonary)\n",
        "          st_list.append(self.words_dictonary[word])\n",
        "            \n",
        "        pt_list = []\n",
        "        for word in row['product_title'].split(' '):\n",
        "          if not (word in self.words_dictonary):\n",
        "            self.words_dictonary[word] = len(self.words_dictonary)\n",
        "          pt_list.append(self.words_dictonary[word])\n",
        "\n",
        "        X1.append(np.reshape(np.pad(st_list,(0,self.padding-len(st_list))),(self.padding,1)))\n",
        "        X2.append(np.reshape(np.pad(pt_list,(0,self.padding-len(pt_list))),(self.padding,1)))\n",
        "        # assume there's one document per line, tokens separated by whitespace\n",
        "        if (index + 1) % self.batch_size == 0:\n",
        "          y=np.array(y)\n",
        "\n",
        "          yield (np.array([X1,X2]),y)\n",
        "          X1 = []\n",
        "          X2 = []\n",
        "          y=[]\n",
        "\n",
        "      y=np.array(y)\n",
        "      if(len(y) > 0):\n",
        "        yield np.array([X1,X2]),y\n",
        "\n",
        "loss_index = 0\n",
        "def rmse(y_true, y_pred):\n",
        "  return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1)) \n",
        "\n",
        "def new_loss(y_actual,y_predicted):\n",
        "  global loss_index\n",
        "  global y_train\n",
        "  global X1_train\n",
        "  global X2_train\n",
        "\n",
        "  cosine_loss = tf.keras.losses.CosineSimilarity(axis=1)\n",
        "  loss = tf.constant(0.0)\n",
        "  m = tf.constant(-0.00015)\n",
        "  x = tf.constant(0.0)\n",
        "  K.switch(tf.constant(y_train[x]))\n",
        "  for i in range(32):\n",
        "    if (True):\n",
        "      loss = tf.add(loss,tf.subtract(tf.constant(1.0),\n",
        "                                     cosine_loss(np.float32(X1_train[loss_index+i]),np.float32(X2_train[loss_index+i]))))\n",
        "    else:\n",
        "      loss = tf.add(loss,tf.maximum(tf.constant(0.0),\n",
        "                                    tf.subtract(cosine_loss(np.float32(X1_train[loss_index+i]), np.float32(X2_train[loss_index+i])),m)))\n",
        "  loss_index+=32\n",
        "  with open('log.log', 'a') as file:\n",
        "    json.dump(loss_index, file)\n",
        "  tf.Print(loss,[loss],(\"%s\" %loss_index))\n",
        "  #return tf.add(K.sum(tf.multiply(tf.constant(0.0),y_predicted)),loss)\n",
        "  return cosine_loss(y_actual,y_predicted)\n",
        "\n",
        "# siames_model=network(max_input_len)\n",
        "# siames_model.summary()\n",
        "# siames_model.compile(loss=new_loss ,optimizer='adam',metrics=['mae','accuracy'])\n",
        "# model_hist = siames_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=3,batch_size=32,validation_data=([X1_test,X2_test],y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmViaexjMFqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myGen=MyCharGenerator(padding=147,df=train,batch_size=1)\n",
        "it = iter(myGen)\n",
        "\n",
        "X1 = []\n",
        "X2 = []\n",
        "Y = []\n",
        "for time in range(len(train)):\n",
        "  [X1_gen,X2_gen],y_gen = next(it)\n",
        "  X1.append([X for X in X1_gen[0]])\n",
        "  X2.append([X for X in X2_gen[0]])\n",
        "  Y.append(y_gen[0])\n",
        "\n",
        "X1_train,X1_test,X2_train,X2_test,y_train,y_test = train_test_split(X1,X2,Y,test_size=0.2)\n",
        "\n",
        "X1_train = np.array(X1_train)\n",
        "X2_train = np.array(X2_train)\n",
        "y_train = np.array(y_train)\n",
        "X1_test = np.array(X1_test)\n",
        "X2_test = np.array(X2_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeiZtPowPSYF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def network(n_fetures,n_described=1):\n",
        "  inp=Input(shape=(n_fetures,n_described))\n",
        "  x = CuDNNLSTM(n_fetures)(inp)\n",
        "  x = Reshape((n_fetures,1))(x)\n",
        "  x=Conv1D(filters=32,kernel_size=10,activation='relu')(x)\n",
        "  x=MaxPool1D()(x)\n",
        "  x=Conv1D(filters=64,kernel_size=10,activation='relu')(x)\n",
        "  x=MaxPool1D()(x)\n",
        "  x=Conv1D(filters=128,kernel_size=10,activation='relu')(x)\n",
        "  x=Flatten()(x)\n",
        "  x=Dense(128,activation='relu')(x)\n",
        "  model= Model(inp,x)\n",
        "\n",
        "  search_term_input=Input(shape=(n_fetures,n_described),name='inp1')\n",
        "  product_title_input=Input(shape=(n_fetures,n_described),name='inp2')\n",
        "\n",
        "  search_term_encoded=model(search_term_input)\n",
        "  product_title_encoded=model(product_title_input)\n",
        "\n",
        "\n",
        "  x_connected=Concatenate()([search_term_encoded,product_title_encoded])\n",
        "  x_connected=Dense(1,activation='sigmoid')(x_connected)\n",
        "  \n",
        "  \n",
        "  connected_model=Model(inputs=[search_term_input,product_title_input],output=x_connected)\n",
        "  connected_model.summary()\n",
        "\n",
        "  return connected_model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UW61vXdshpw",
        "colab_type": "code",
        "outputId": "59c7391c-8ba7-4154-8874-11bb804ed7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        }
      },
      "source": [
        "siames_model=network(max_input_len)\n",
        "siames_model.summary()\n",
        "siames_model.compile(loss='msle' ,optimizer='adam',metrics=['mae','accuracy',rmse])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            257         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 535,593\n",
            "Trainable params: 535,593\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            257         concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 535,593\n",
            "Trainable params: 535,593\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1702: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1J12Mt37hMd",
        "colab_type": "code",
        "outputId": "154f9509-8196-4ef5-8a2a-f75609689e83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "model_hist = siames_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=1,batch_size=20,validation_data=([X1_test,X2_test],y_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 59253 samples, validate on 14814 samples\n",
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            " - 74s - loss: 0.0296 - mean_absolute_error: 0.2204 - acc: 0.2575 - rmse: 0.2204 - val_loss: 0.0293 - val_mean_absolute_error: 0.2183 - val_acc: 0.2609 - val_rmse: 0.2183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x2RcIqjAXQP",
        "colab_type": "code",
        "outputId": "24af4a9d-b421-4ce7-ca86-8fb9663a004b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        }
      },
      "source": [
        "def get_query(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['query'].values\n",
        "def get_title(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['title'].values\n",
        "\n",
        "Naive_X = []\n",
        "Naive_Y = []\n",
        "\n",
        "for index,row in train.iterrows():\n",
        "  Naive_Y.append(row['relevance'])\n",
        "  Naive_X.append([''.join(list(row['search_term'])),''.join(list(row['product_title']))])\n",
        "\n",
        "X_naive_train,X_naive_test,y_naive_train,y_naive_test = train_test_split(Naive_X,Naive_Y,test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "     ('fetures',\n",
        "         FeatureUnion(\n",
        "             [\n",
        "                 ('later',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                          ('query',FunctionTransformer(get_query)),\n",
        "                          ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False,analyzer='char'))\n",
        "                      ]\n",
        "                  )),\n",
        "                 ('bins',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                       ('title',FunctionTransformer(get_title)),\n",
        "                       ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False,analyzer='char'))\n",
        "                      ]\n",
        "                  )\n",
        "                 )\n",
        "             ]\n",
        "         )\n",
        "      ),\n",
        "     ('clf', LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "naive_model = cross_validate(pipeline, X_naive_train, y_naive_train, cv=5,return_estimator=True)\n",
        "\n",
        "predictions = naive_model['estimator'][4].predict(X_naive_test)\n",
        "mae = np.absolute((np.array(y_naive_test)-np.array(predictions))).mean()\n",
        "\n",
        "\n",
        "\n",
        "rmse = math.sqrt(((np.array(y_naive_test)-np.array(predictions))**2).mean())\n",
        "print(\"MAE: %.3f\" %mae)\n",
        "print(\"RMSE: %.3f\" %rmse)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a35fc658635f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmae2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_naive_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mae2' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJkyvr0ndy-D",
        "colab_type": "code",
        "outputId": "a9789823-929f-4268-e684-e41c195d17fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "siames_model_ML = Model(siames_model.input,siames_model.layers[-2].output)\n",
        "siames_model_ML.compile(loss='mse',optimizer='SGD')\n",
        "siames_model_ML.summary()\n",
        "\n",
        "\n",
        "ml_predictions_train = siames_model_ML.predict([X1_train,X2_train])\n",
        "ml_predictions_test = siames_model_ML.predict([X1_test,X2_test])\n",
        "\n",
        "\n",
        "# siames_model_ML=network(max_input_len)\n",
        "# siames_model_ML.layers.pop(-1)\n",
        "# siames_model_ML.summary()\n",
        "# siames_model_ML.compile(optimizer='SGD',metrics=['mae','accuracy',rmse])\n",
        "# model_hist_ml = siames_model_ML.fit([X1_train,X2_train],y_train,verbose=2,epochs=10,batch_size=20,validation_data=([X1_test,X2_test],y_test))\n",
        "\n",
        "\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inp1 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "inp2 (InputLayer)               (None, 147, 1)       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "model_1 (Model)                 (None, 128)          535336      inp1[0][0]                       \n",
            "                                                                 inp2[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 256)          0           model_1[1][0]                    \n",
            "                                                                 model_1[2][0]                    \n",
            "==================================================================================================\n",
            "Total params: 535,336\n",
            "Trainable params: 535,336\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "CPU times: user 16.9 s, sys: 972 ms, total: 17.8 s\n",
            "Wall time: 14.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqKhxc5p7R_C",
        "colab_type": "code",
        "outputId": "13fd0cd0-6267-45ff-e97a-6c2413b7dbcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "ml_knn_model = KNeighborsRegressor(n_jobs=16,weights='distance',algorithm='kd_tree',n_neighbors=3)\n",
        "ml_knn_model.fit(ml_predictions_train,y_train*2+1)\n",
        "ml_knn_predictions = ml_knn_model.predict(ml_predictions_test)\n",
        "\n",
        "y_t=np.array(y_test)*2+1\n",
        "mae_knn = np.absolute((y_t-np.array(ml_knn_predictions))).mean()\n",
        "rmse_knn = math.sqrt(((y_t-np.array(ml_knn_predictions))**2).mean())\n",
        "\n",
        "print(\"KNN MAE: %.3f\" %mae_knn)\n",
        "print(\"KNN RMSE: %.3f\" %rmse_knn)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KNN MAE: 0.441\n",
            "KNN RMSE: 0.543\n",
            "CPU times: user 7min 57s, sys: 269 ms, total: 7min 58s\n",
            "Wall time: 4min 11s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "no-lvCoQFysh",
        "colab_type": "code",
        "outputId": "6683a9f4-e893-47c3-f5eb-fc02bfa0f491",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "unique, counts = np.unique(ml_knn_predictions, return_counts=True)\n",
        "print (unique)\n",
        "print (counts)\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.         1.165      1.20060037 1.31999395 1.33       1.33408628\n",
            " 1.33986438 1.35122882 1.38271399 1.44666667 1.48315    1.49833468\n",
            " 1.5        1.50370373 1.55333333 1.55666667 1.58596288 1.6020242\n",
            " 1.62893108 1.64840037 1.65071362 1.65953642 1.66043196 1.665\n",
            " 1.66666667 1.66673538 1.67       1.69939806 1.72860407 1.73288201\n",
            " 1.73570589 1.7644921  1.76572408 1.7711161  1.77666667 1.77666667\n",
            " 1.77674769 1.78       1.78087149 1.78454545 1.78690324 1.78880868\n",
            " 1.79307365 1.80501487 1.83       1.83171668 1.83468029 1.835\n",
            " 1.83870058 1.84271902 1.8457732  1.84690334 1.86023374 1.86494405\n",
            " 1.87095401 1.88291093 1.88540315 1.88666667 1.89       1.89247975\n",
            " 1.89907025 1.91166503 1.92803134 1.93527859 1.94360823 1.9562512\n",
            " 1.96018265 1.96038914 1.96181059 1.97040687 1.97775777 1.97987284\n",
            " 1.99138608 2.         2.         2.         2.0025     2.00416414\n",
            " 2.00641327 2.01379121 2.0141841  2.01565451 2.02936778 2.03946262\n",
            " 2.04580489 2.0469524  2.05525241 2.06358264 2.06637421 2.06789787\n",
            " 2.06843473 2.07870077 2.08048947 2.08774083 2.09083419 2.09154258\n",
            " 2.09321721 2.09418538 2.09629863 2.09884349 2.10248535 2.10498943\n",
            " 2.10647764 2.10750258 2.11       2.11       2.11260798 2.11291409\n",
            " 2.11333333 2.11821831 2.12108347 2.12205948 2.12600849 2.12624396\n",
            " 2.12647273 2.12934886 2.13228515 2.13270216 2.15231962 2.15240432\n",
            " 2.15242945 2.15811328 2.16380827 2.16455678 2.1647293  2.165\n",
            " 2.16634318 2.16821991 2.17       2.17137194 2.17173203 2.17333117\n",
            " 2.17775982 2.18043923 2.18135791 2.1815467  2.18177125 2.18311726\n",
            " 2.18349555 2.1873422  2.19003723 2.1907687  2.19147066 2.19176393\n",
            " 2.1922598  2.1928568  2.1951941  2.19781406 2.19857425 2.19982681\n",
            " 2.20270184 2.202956   2.20323973 2.20444173 2.20476677 2.20883493\n",
            " 2.21226672 2.21299859 2.2138638  2.21413387 2.21525044 2.21533453\n",
            " 2.21538581 2.21660129 2.22       2.22       2.22146237 2.22195288\n",
            " 2.22243137 2.22333333 2.22333333 2.22451581 2.22609114 2.22880234\n",
            " 2.22942104 2.23009555 2.23345199 2.23469271 2.23520036 2.23531013\n",
            " 2.23754049 2.2416444  2.24272727 2.24304386 2.24847036 2.24939319\n",
            " 2.25149722 2.25282948 2.25363695 2.25990675 2.26306052 2.26337484\n",
            " 2.26372249 2.26604479 2.26831586 2.28015112 2.28033944 2.28910431\n",
            " 2.29289322 2.29651117 2.29921056 2.3        2.30251932 2.30318163\n",
            " 2.30349666 2.30433452 2.30566936 2.30929521 2.30960908 2.31204174\n",
            " 2.31259051 2.31282556 2.31415307 2.31449267 2.31508599 2.31542137\n",
            " 2.31789765 2.31823853 2.31901397 2.32114651 2.32155534 2.32208269\n",
            " 2.32326304 2.3242939  2.32851929 2.32902259 2.32994898 2.33\n",
            " 2.33       2.33031347 2.33039376 2.3309607  2.3310751  2.33202567\n",
            " 2.3325     2.33290854 2.33308084 2.33331378 2.33333333 2.33345492\n",
            " 2.33374569 2.334      2.335      2.33580264 2.33666667 2.33676889\n",
            " 2.33688392 2.33807726 2.33843047 2.34527004 2.34549191 2.34784136\n",
            " 2.34882256 2.3509284  2.35101056 2.35192202 2.3544298  2.35884832\n",
            " 2.36548661 2.36946251 2.36946523 2.3706845  2.37194338 2.38045545\n",
            " 2.3869484  2.3887206  2.38923049 2.39151739 2.39676281 2.39851891\n",
            " 2.3993505  2.40032539 2.40334122 2.40399674 2.40567237 2.40609516\n",
            " 2.40637765 2.41206961 2.41773741 2.41929148 2.41995192 2.42018859\n",
            " 2.42123485 2.42264881 2.42851958 2.43015889 2.43159105 2.43166928\n",
            " 2.43311018 2.43521295 2.43536168 2.43736076 2.43782    2.44179552\n",
            " 2.44195228 2.44207512 2.44333333 2.44549405 2.44551285 2.44666667\n",
            " 2.44666667 2.44993791 2.45001681 2.45030965 2.45125864 2.45282654\n",
            " 2.45304107 2.45438145 2.45440778 2.4545805  2.45601434 2.45646793\n",
            " 2.45954023 2.45967216 2.468      2.47315544 2.4732085  2.47497269\n",
            " 2.476502   2.4784266  2.5        2.50344755 2.5037979  2.50392758\n",
            " 2.51011605 2.51183446 2.51434002 2.51483938 2.51805267 2.51856279\n",
            " 2.51883026 2.52176443 2.53135383 2.53361641 2.53371487 2.53684445\n",
            " 2.53829234 2.5397881  2.5400332  2.54026378 2.5432458  2.54383152\n",
            " 2.54476311 2.55030234 2.55068086 2.55139844 2.55143498 2.55179903\n",
            " 2.55291994 2.55297727 2.55306657 2.55333333 2.55360721 2.55396659\n",
            " 2.55419358 2.55666667 2.55666667 2.55673098 2.55681125 2.55690859\n",
            " 2.55695383 2.55947962 2.55961151 2.56191402 2.56199656 2.56416929\n",
            " 2.56429467 2.56474228 2.56560885 2.56565079 2.5659977  2.56888433\n",
            " 2.57       2.57192223 2.57311803 2.57765038 2.57770931 2.58530312\n",
            " 2.59152487 2.59264952 2.59972507 2.60885855 2.61816432 2.621606\n",
            " 2.6219294  2.62248438 2.62261385 2.62444642 2.6272229  2.63359034\n",
            " 2.6359169  2.64172121 2.64291568 2.64440325 2.64449721 2.64830958\n",
            " 2.64853495 2.65081585 2.65588135 2.65999241 2.65999417 2.66132702\n",
            " 2.66224266 2.66242899 2.66353243 2.66368244 2.66443691 2.66450833\n",
            " 2.66499113 2.665      2.66532805 2.66598209 2.66600264 2.6664483\n",
            " 2.66652963 2.66666667 2.66666667 2.66666802 2.66773069 2.66805415\n",
            " 2.67       2.67       2.67007693 2.67296894 2.6738747  2.67943464\n",
            " 2.68049658 2.68057215 2.68865927 2.69075454 2.69408634 2.70129151\n",
            " 2.70634796 2.71630623 2.71645776 2.71722506 2.72727273 2.7283979\n",
            " 2.73729748 2.74034636 2.75596446 2.75629463 2.76416933 2.76431453\n",
            " 2.76722123 2.77149296 2.77173757 2.77666667 2.77681702 2.77773785\n",
            " 2.77792037 2.77903498 2.77993684 2.78       2.78       2.78391843\n",
            " 2.78512101 2.78643573 2.78723962 2.78868656 2.79099099 2.79377236\n",
            " 2.79555143 2.80224923 2.80238764 2.80261444 2.80376291 2.80403874\n",
            " 2.80621909 2.80791164 2.80911134 2.80937303 2.82230769 2.83067106\n",
            " 2.835      2.84585139 2.846727   2.84738565 2.84788603 2.85353152\n",
            " 2.86642164 2.86720421 2.8704159  2.87283371 2.87862784 2.88014691\n",
            " 2.88258147 2.89       2.89       2.89110025 2.90552859 2.90973034\n",
            " 2.91308927 2.92301116 2.95523376 2.97039162 2.98268608 3.\n",
            " 3.         3.        ]\n",
            "[    3     1     1     1    17     1     1     1     1     1     1     1\n",
            "     3     1     1     1     1     1     1     1     1     1     1     2\n",
            "     6     1    22     1     1     1     1     1     1     1     9     2\n",
            "     1     2     1     1     1     1     1     1     1     1     2     2\n",
            "     1     1     1     1     1     1     1     1     1     4    17     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1    86     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1    13     1     1     1\n",
            "     8     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1    10     1     1     6     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1    11     1     1\n",
            "     1    26     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     2     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     2     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1    97\n",
            "     1     1     1     1     2     1     1     1     1     1 13597     1\n",
            "     2     1     2     1     1     1     2     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     2     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     2     1     1     1     1    39     1     1     1\n",
            "    18     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1    21     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     6     1     1     1    41     1     1     1     1\n",
            "     1     1     1     1     1     1     1     2     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     2     1     1     2     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1    13     1     1     1     1     1    28     2     1     1     1\n",
            "    97     2     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1    10     1     1     1     1     1    23     1     1\n",
            "     1     1     2     1     1     1     1     1     1     1     1     1\n",
            "     1     1     1     1     1     1    17     1     1     1     1     1\n",
            "     1     1     1     1     1     1     1     7     1     1     1     1\n",
            "     1     1     1     1     2     1    69     1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4isaQ4R8AJi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb794a7b-237a-48a8-a10f-fbfdde1b214e"
      },
      "source": [
        "ml_predictions_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59253, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_xPOgCx7zx7",
        "colab_type": "code",
        "outputId": "a43b338c-cc1d-45fe-bc16-b812581bf4b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "\n",
        "ml_rf_model = RandomForestRegressor(n_jobs=16,min_samples_leaf=10, max_depth = 3,n_estimators=10)\n",
        "ml_rf_model.fit(ml_predictions_train,y_train*2+1)\n",
        "ml_rf_predictions = ml_rf_model.predict(ml_predictions_test)\n",
        "\n",
        "y_t_rf=y_test*2+1\n",
        "\n",
        "mae_rf = np.absolute((np.array(y_t_rf)-np.array(ml_rf_predictions))).mean()\n",
        "rmse_rf = math.sqrt(((np.array(y_t_rf)-np.array(ml_rf_predictions))**2).mean())\n",
        "\n",
        "\n",
        "print(\"RANDOM MAE: %.3f\" %mae_rf)\n",
        "print(\"RANDOM RMSE: %.3f\" %rmse_rf)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-321aa637b0aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n\\nml_rf_model = RandomForestRegressor(n_jobs=16,min_samples_leaf=10, max_depth = 3,n_estimators=10)\\nml_rf_model.fit(ml_predictions_train,y_train*2+1)\\nml_rf_predictions = ml_rf_model.predict(ml_predictions_test)\\n\\ny_t_rf=y_test*2+1\\n\\nmae_rf = np.absolute((np.array(y_t_rf)-np.array(ml_rf_predictions))).mean()\\nrmse_rf = math.sqrt(((np.array(y_t_rf)-np.array(ml_rf_predictions))**2).mean())\\n\\n\\nprint(\"RANDOM MAE: %.3f\" %mae_rf)\\nprint(\"RANDOM RMSE: %.3f\" %rmse_rf)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eH7hO98KaTqr",
        "colab_type": "text"
      },
      "source": [
        "We explored the data and decided we need to do some preprocessing\n",
        "\n",
        "we found some examples for words that ment the same thing but were wrote differently.\n",
        "\n",
        "for example in the 'product title' column there is no 'inches' there is 'in.'\n",
        "but in the 'search term' there is 'inches'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s1DYXGkZDFZ",
        "colab_type": "code",
        "outputId": "b7ba975b-dd8c-4243-a282-ed5a39b9df46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        }
      },
      "source": [
        " print ('\\'product_titles\\' contains \\'inches\\'')\n",
        " display(train.loc[train['product_title'].str.contains(' inches ')])\n",
        " print ('\\n\\n\\n\\'search_terms\\' contains \\'inches\\'')\n",
        " display(train.loc[train['search_term'].str.contains(' inches ')].head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'product_titles' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [id, product_uid, product_title, search_term, relevance, norm_relevance]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "'search_terms' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4015</th>\n",
              "      <td>12507</td>\n",
              "      <td>102193</td>\n",
              "      <td>Samsung 28.15 cu. ft. 4-Door French Door Refri...</td>\n",
              "      <td>33 inches wide samsung</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13646</th>\n",
              "      <td>42206</td>\n",
              "      <td>110179</td>\n",
              "      <td>JELD-WEN Smooth 4-Panel Primed Molded Interior...</td>\n",
              "      <td>interior doors 82 inches in length</td>\n",
              "      <td>2.33</td>\n",
              "      <td>0.665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14917</th>\n",
              "      <td>46069</td>\n",
              "      <td>111389</td>\n",
              "      <td>Paslode 3 in. x 0.131-Gauge 30å¡ Brite Smooth ...</td>\n",
              "      <td>3 .5 inches paper tape collated</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15609</th>\n",
              "      <td>48121</td>\n",
              "      <td>112069</td>\n",
              "      <td>Roberts Laminate Cutter for Cross Cutting up t...</td>\n",
              "      <td>metric to inches converter</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17099</th>\n",
              "      <td>52792</td>\n",
              "      <td>113648</td>\n",
              "      <td>Masonite 30 in. x 80 in. Textured 6-Panel Holl...</td>\n",
              "      <td>interior doors 82 inches in length</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  product_uid  ... relevance norm_relevance\n",
              "4015   12507       102193  ...      2.67          0.835\n",
              "13646  42206       110179  ...      2.33          0.665\n",
              "14917  46069       111389  ...      2.00          0.500\n",
              "15609  48121       112069  ...      1.67          0.335\n",
              "17099  52792       113648  ...      2.67          0.835\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0-tgTBOiUBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def preprocess_sentences(s):\n",
        "  s = s.lower()\n",
        "  s = re.sub(r\"(\\d+)'\",r'\\1in.',s)\n",
        "  s = s.replace(\"inches\",\"in.\") \n",
        "  s = s.replace(\"inch\",\"in.\")\n",
        "  s = s.replace(\" in \",\"in. \") \n",
        "  s = s.replace(\" in.\",\"in.\") \n",
        "\n",
        "  s = s.replace(\"''\",\"ft.\") \n",
        "  s = s.replace(\" feet \",\"ft. \") \n",
        "  s = s.replace(\"feet\",\"ft.\") \n",
        "  s = s.replace(\"foot\",\"ft.\") \n",
        "  s = s.replace(\" ft \",\"ft. \") \n",
        "  s = s.replace(\" ft.\",\"ft.\") \n",
        "\n",
        "  s = s.replace(\" pounds \",\"lb. \")\n",
        "  s = s.replace(\" pound \",\"lb. \") \n",
        "  s = s.replace(\"pound\",\"lb.\") \n",
        "  s = s.replace(\" lb \",\"lb. \") \n",
        "  s = s.replace(\" lb.\",\"lb.\") \n",
        "  s = s.replace(\" lbs \",\"lb. \") \n",
        "  s = s.replace(\"lbs.\",\"lb.\") \n",
        "\n",
        "  s = s.replace(\" x \",\" xby \")\n",
        "  s = s.replace(\"*\",\" xby \")\n",
        "  s = s.replace(\" by \",\" xby\")\n",
        "  s = s.replace(\"x0\",\" xby 0\")\n",
        "  s = s.replace(\"x1\",\" xby 1\")\n",
        "  s = s.replace(\"x2\",\" xby 2\")\n",
        "  s = s.replace(\"x3\",\" xby 3\")\n",
        "  s = s.replace(\"x4\",\" xby 4\")\n",
        "  s = s.replace(\"x5\",\" xby 5\")\n",
        "  s = s.replace(\"x6\",\" xby 6\")\n",
        "  s = s.replace(\"x7\",\" xby 7\")\n",
        "  s = s.replace(\"x8\",\" xby 8\")\n",
        "  s = s.replace(\"x9\",\" xby 9\")\n",
        "  s = s.replace(\"0x\",\"0 xby \")\n",
        "  s = s.replace(\"1x\",\"1 xby \")\n",
        "  s = s.replace(\"2x\",\"2 xby \")\n",
        "  s = s.replace(\"3x\",\"3 xby \")\n",
        "  s = s.replace(\"4x\",\"4 xby \")\n",
        "  s = s.replace(\"5x\",\"5 xby \")\n",
        "  s = s.replace(\"6x\",\"6 xby \")\n",
        "  s = s.replace(\"7x\",\"7 xby \")\n",
        "  s = s.replace(\"8x\",\"8 xby \")\n",
        "  s = s.replace(\"9x\",\"9 xby \")\n",
        "\n",
        "  s = s.replace(\" sq ft\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq ft\",\"sq.ft. \")\n",
        "  s = s.replace(\"sqft\",\"sq.ft. \")\n",
        "  s = s.replace(\" sqft \",\"sq.ft. \") \n",
        "  s = s.replace(\"sq. ft\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq ft.\",\"sq.ft. \") \n",
        "  s = s.replace(\"sq feet\",\"sq.ft. \") \n",
        "  s = s.replace(\"square feet\",\"sq.ft. \") \n",
        "\n",
        "  s = s.replace(\" gallons \",\"gal. \") \n",
        "  s = s.replace(\" gallon \",\"gal. \") \n",
        "  s = s.replace(\"gallons\",\"gal.\") \n",
        "  s = s.replace(\"gallon\",\"gal.\") \n",
        "  s = s.replace(\" gal \",\"gal. \") \n",
        "  s = s.replace(\" gal\",\"gal.\") \n",
        "\n",
        "  s = s.replace(\"ounces\",\"oz.\")\n",
        "  s = s.replace(\"ounce\",\"oz.\")\n",
        "  s = s.replace(\" oz.\",\"oz. \")\n",
        "  s = s.replace(\" oz \",\"oz. \")\n",
        "\n",
        "  s = s.replace(\"centimeters\",\"cm.\")    \n",
        "  s = s.replace(\" cm.\",\"cm.\")\n",
        "  s = s.replace(\" cm \",\"cm. \")\n",
        "  \n",
        "  s = s.replace(\"milimeters\",\"mm.\")\n",
        "  s = s.replace(\" mm.\",\"mm.\")\n",
        "  s = s.replace(\" mm \",\"mm. \")\n",
        "  \n",
        "  s = s.replace(\"°\",\"deg. \")\n",
        "  s = s.replace(\"degrees\",\"deg. \")\n",
        "  s = s.replace(\"degree\",\"deg. \")\n",
        "  \n",
        "  s = s.replace(\"volts\",\"volt. \")\n",
        "  s = s.replace(\"volt\",\"volt. \")\n",
        "\n",
        "  s = s.replace(\"watts\",\"watt. \")\n",
        "  s = s.replace(\"watt\",\"watt. \")\n",
        "\n",
        "  return s"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwU0AA9eooKS",
        "colab_type": "code",
        "outputId": "6a1922fe-46cd-468d-b5f5-8cdd6e2e168e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "processed_train = train.copy()\n",
        "processed_train['search_term'] = processed_train['search_term'].map(lambda x:preprocess_sentences(x))\n",
        "processed_train['product_title'] = processed_train['product_title'].map(lambda x:preprocess_sentences(x))\n",
        "\n",
        "print ('\\'product_titles\\' contains \\'inches\\'')\n",
        "display(processed_train.loc[processed_train['product_title'].str.contains(' in. ')])\n",
        "print ('\\n\\n\\n\\'search_terms\\' contains \\'inches\\'')\n",
        "display(processed_train.loc[processed_train['search_term'].str.contains(' in. ')].head(5))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'product_titles' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18498</th>\n",
              "      <td>57112</td>\n",
              "      <td>115108</td>\n",
              "      <td>ready-strip 32oz.  environmentally friendly dr...</td>\n",
              "      <td>adhesive slide strip</td>\n",
              "      <td>1.67</td>\n",
              "      <td>0.335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25119</th>\n",
              "      <td>77115</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>12in. ceiling tile</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25120</th>\n",
              "      <td>77121</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>sound dampening</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25121</th>\n",
              "      <td>77123</td>\n",
              "      <td>122211</td>\n",
              "      <td>bonded logic inc ultrasonic 12in. xby 12in. ac...</td>\n",
              "      <td>sounds panels</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67581</th>\n",
              "      <td>202995</td>\n",
              "      <td>191353</td>\n",
              "      <td>mohawk home ink swirl cocoa 2ft. xby 8ft. runner</td>\n",
              "      <td>rug ruunners</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ... relevance norm_relevance\n",
              "18498   57112       115108  ...      1.67          0.335\n",
              "25119   77115       122211  ...      2.00          0.500\n",
              "25120   77121       122211  ...      2.67          0.835\n",
              "25121   77123       122211  ...      2.00          0.500\n",
              "67581  202995       191353  ...      2.00          0.500\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "'search_terms' contains 'inches'\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>product_uid</th>\n",
              "      <th>product_title</th>\n",
              "      <th>search_term</th>\n",
              "      <th>relevance</th>\n",
              "      <th>norm_relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42161</th>\n",
              "      <td>128340</td>\n",
              "      <td>144629</td>\n",
              "      <td>liberty 20in. european self-closing drawer sli...</td>\n",
              "      <td>18.75 in. drawer slides</td>\n",
              "      <td>2.67</td>\n",
              "      <td>0.835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54368</th>\n",
              "      <td>164835</td>\n",
              "      <td>164764</td>\n",
              "      <td>kaleen matira blue 2ft. xby 3ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>2.00</td>\n",
              "      <td>0.500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55418</th>\n",
              "      <td>167918</td>\n",
              "      <td>166665</td>\n",
              "      <td>kaleen matira blue 2ft. xby 3ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60397</th>\n",
              "      <td>182300</td>\n",
              "      <td>176124</td>\n",
              "      <td>kaleen matira blue 3ft. xby 5ft. indoor/outdoo...</td>\n",
              "      <td>kaleen rugs, inc matira area rug 3 x</td>\n",
              "      <td>3.00</td>\n",
              "      <td>1.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  product_uid  ... relevance norm_relevance\n",
              "42161  128340       144629  ...      2.67          0.835\n",
              "54368  164835       164764  ...      2.00          0.500\n",
              "55418  167918       166665  ...      3.00          1.000\n",
              "60397  182300       176124  ...      3.00          1.000\n",
              "\n",
              "[4 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxC6_oHYqgFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_product_title_len=processed_train.product_title.map(lambda x: len(x.split(' '))).max()\n",
        "max_search_term=processed_train.search_term.map(lambda x: len(x.split(' '))).max()\n",
        "max_input_len=max(max_product_title_len,max_search_term,70)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHoxrjE4AAxO",
        "colab_type": "code",
        "outputId": "98cb133f-0beb-49bb-869f-c6bb37cd3faf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "myGen=MyWordGenerator(padding=max_input_len,df=processed_train,batch_size=1)\n",
        "it = iter(myGen)\n",
        "\n",
        "X1 = []\n",
        "X2 = []\n",
        "Y = []\n",
        "for time in range(len(processed_train)):\n",
        "  [X1_gen,X2_gen],y_gen = next(it)\n",
        "  X1.append([X for X in X1_gen[0]])\n",
        "  X2.append([X for X in X2_gen[0]])\n",
        "  Y.append(y_gen[0])\n",
        "\n",
        "X1_train,X1_test,X2_train,X2_test,y_train,y_test = train_test_split(X1,X2,Y,test_size=0.2)\n",
        "\n",
        "X1_train = np.array(X1_train)\n",
        "X2_train = np.array(X2_train)\n",
        "y_train = np.array(y_train)\n",
        "X1_test = np.array(X1_test)\n",
        "X2_test = np.array(X2_test)\n",
        "y_test = np.array(y_test)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-4024bfbb62c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessed_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0;34m[\u001b[0m\u001b[0mX1_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mX1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX1_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mX2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX2_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-75-c1b9575c9784>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m           \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m           \u001b[0;32myield\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m           \u001b[0mX1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m           \u001b[0mX2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ks8aV-82vmUc",
        "colab_type": "code",
        "outputId": "bb06d447-2224-48d6-fea4-42c7c019d938",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 832
        }
      },
      "source": [
        "def embedding_input(name, n_in, n_out, reg=1e-4):\n",
        "    inp = Input(shape=(70,1), dtype='int64', name=name)\n",
        "    x = Flatten()(inp)\n",
        "    return inp, Embedding(n_in, n_out, input_length=70, embeddings_regularizer=l2(reg))(x)\n",
        "\n",
        "query_inp,query_emb = embedding_input(\"query\",len(processed_train.search_term.unique()),50)\n",
        "title_inp,title_emb = embedding_input(\"title\",len(processed_train.product_title.unique()),50)\n",
        "x = Concatenate()([query_emb,title_emb])\n",
        "x = Flatten()(x)\n",
        "x = Dense(1,activation='relu')(x)\n",
        "embedding_model = Model([query_inp, title_inp], x)\n",
        "embedding_model.compile(optimizer='adam', loss='msle',metrics=['accuracy',rmse,'mae'])\n",
        "embedding_model.summary()\n",
        "\n",
        "embedding_model_hist = embedding_model.fit([X1_train,X2_train], y_train, batch_size=64, epochs=3, \n",
        "          validation_data=([X1_test,X2_test], y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "query (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "title (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 70)           0           query[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_8 (Flatten)             (None, 70)           0           title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 70, 50)       589450      flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 50)       2673650     flatten_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_5 (Concatenate)     (None, 70, 100)      0           embedding_3[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 7000)         0           concatenate_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1)            7001        flatten_9[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 3,270,101\n",
            "Trainable params: 3,270,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-1fa42c4c032d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m embedding_model_hist = embedding_model.fit([X1_train,X2_train], y_train, batch_size=64, epochs=3, \n\u001b[0;32m---> 16\u001b[0;31m           validation_data=([X1_test,X2_test], y_test))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    139\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected query to have shape (70, 1) but got array with shape (147, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmaWxLgVDWUU",
        "colab_type": "code",
        "outputId": "9c7bf060-e60b-46a5-8173-bdfcedd9d708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "inp=Input(shape=(70,50))\n",
        "x = CuDNNLSTM(70)(inp)\n",
        "x = Reshape((70,1))(x)\n",
        "x=Conv1D(filters=32,kernel_size=10,activation='relu')(x)\n",
        "x=MaxPool1D()(x)\n",
        "x=Conv1D(filters=64,kernel_size=10,activation='relu')(x)\n",
        "x=MaxPool1D()(x)\n",
        "x=Conv1D(filters=128,kernel_size=10,activation='relu')(x)\n",
        "x=Flatten()(x)\n",
        "x=Dense(128,activation='relu')(x)\n",
        "model= Model(inp,x)\n",
        "\n",
        "search_term_encoded=model(query_emb)\n",
        "product_title_encoded=model(title_emb)\n",
        "\n",
        "\n",
        "x_connected=Concatenate()([search_term_encoded,product_title_encoded])\n",
        "x_connected=Dense(1,activation='sigmoid')(x_connected)\n",
        "\n",
        "siames_embedded_model = Model([query_inp,title_inp],x_connected)\n",
        "siames_embedded_model.summary()\n",
        "siames_embedded_model.compile(loss='mse' ,optimizer='adam',metrics=['mae','accuracy',rmse])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_172\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "query (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "title (InputLayer)              (None, 70, 1)        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_32 (Flatten)            (None, 70)           0           query[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "flatten_33 (Flatten)            (None, 70)           0           title[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 70, 50)       589450      flatten_32[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "embedding_4 (Embedding)         (None, 70, 50)       2673650     flatten_33[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "model_171 (Model)               (None, 128)          153616      embedding_3[0][0]                \n",
            "                                                                 embedding_4[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_67 (Concatenate)    (None, 256)          0           model_171[1][0]                  \n",
            "                                                                 model_171[2][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_135 (Dense)               (None, 1)            257         concatenate_67[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 3,416,973\n",
            "Trainable params: 3,416,973\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUxb3proDeoy",
        "colab_type": "code",
        "outputId": "4e92bf3a-e342-4a83-91ca-4d35d37b9428",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "word_model_hist = siames_embedded_model.fit([X1_train,X2_train],y_train,verbose=2,epochs=3,batch_size=32,validation_data=([X1_test,X2_test],y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 59253 samples, validate on 14814 samples\n",
            "Epoch 1/3\n",
            " - 46s - loss: 0.0720 - mean_absolute_error: 0.2197 - acc: 0.2582 - rmse: 0.2197 - val_loss: 0.0709 - val_mean_absolute_error: 0.2185 - val_acc: 0.2578 - val_rmse: 0.2185\n",
            "Epoch 2/3\n",
            " - 33s - loss: 0.0715 - mean_absolute_error: 0.2190 - acc: 0.2583 - rmse: 0.2190 - val_loss: 0.0717 - val_mean_absolute_error: 0.2209 - val_acc: 0.2578 - val_rmse: 0.2209\n",
            "Epoch 3/3\n",
            " - 34s - loss: 0.0715 - mean_absolute_error: 0.2191 - acc: 0.2583 - rmse: 0.2191 - val_loss: 0.0709 - val_mean_absolute_error: 0.2189 - val_acc: 0.2578 - val_rmse: 0.2189\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38OlCiMwDr42",
        "colab_type": "code",
        "outputId": "cb050659-0298-4a27-b1fb-4bbe4bd9074b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def get_query(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['query'].values\n",
        "def get_title(X):\n",
        "  return pd.DataFrame(X,columns=['query','title'])['title'].values\n",
        "\n",
        "Naive_X = []\n",
        "Naive_Y = []\n",
        "for index,row in processed_train.iterrows():\n",
        "  Naive_Y.append(row['relevance'])\n",
        "  Naive_X.append([row['search_term'],row['product_title']])\n",
        "\n",
        "X_naive_train,X_naive_test,y_naive_train,y_naive_test = train_test_split(Naive_X,Naive_Y,test_size=0.2)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "     ('fetures',\n",
        "         FeatureUnion(\n",
        "             [\n",
        "                 ('later',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                          ('query',FunctionTransformer(get_query)),\n",
        "                          ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False))\n",
        "                      ]\n",
        "                  )),\n",
        "                 ('bins',\n",
        "                  Pipeline(\n",
        "                      [\n",
        "                       ('title',FunctionTransformer(get_title)),\n",
        "                       ('vect', CountVectorizer(stop_words=[' '], max_df=0.5, max_features=5000,lowercase=False))\n",
        "                      ]\n",
        "                  )\n",
        "                 )\n",
        "             ]\n",
        "         )\n",
        "      ),\n",
        "     ('clf', LinearRegression()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "naive_word_model = cross_validate(pipeline, X_naive_train ,y_naive_train, cv=3,return_estimator=True)\n",
        "\n",
        "predictions = naive_word_model['estimator'][2].predict(X_naive_test)\n",
        "mae = np.absolute((np.array(y_naive_test)-np.array(predictions))).mean()\n",
        "rmse = math.sqrt(((np.array(y_naive_test)-np.array(predictions))**2).mean())\n",
        "print(\"MAE: %.3f\" %mae)\n",
        "print(\"RMSE: %.3f\" %rmse)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 0.427\n",
            "RMSE: 0.538\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3xSbRkPDxE8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "siames_word_model_ML = Model(siames_embedded_model.input,siames_embedded_model.layers[-2].output)\n",
        "siames_word_model_ML.compile(optimizer='SGD')\n",
        "siames_word_model_ML.summary()\n",
        "\n",
        "\n",
        "word_ml_predictions_train = siames_word_model_ML.predict([X1_train,X2_train])\n",
        "word_ml_predictions_test = siames_word_model_ML.predict([X1_test,X2_test])\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cuwb4iyb0XNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml_knn_word_model = KNeighborsRegressor(n_jobs=16,weights='distance',algorithm='kd_tree',n_neighbors=3)\n",
        "ml_knn_word_model.fit(word_ml_predictions_train,y_train)\n",
        "word_ml_knn_predictions = ml_knn_word_model.predict(word_ml_predictions_test)\n",
        "\n",
        "word_mae_knn = np.absolute((np.array(y_naive_test)-np.array(word_ml_knn_predictions))).mean()\n",
        "word_rmse_knn = math.sqrt(((np.array(y_naive_test)-np.array(word_ml_knn_predictions))**2).mean())\n",
        "\n",
        "\n",
        "print(\"KNN MAE: %.3f\" %word_mae_knn)\n",
        "print(\"KNN RMSE: %.3f\" %word_rmse_knn)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVidAaHZ0gR8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml_rf_word_model = RandomForestRegressor()\n",
        "ml_rf_word_model.fit(word_ml_predictions_train,y_train)\n",
        "word_ml_rf_predictions = ml_rf_word_model.predict(word_ml_predictions_test)\n",
        "\n",
        "word_mae_rf = np.absolute((np.array(y_naive_test)-np.array(word_ml_rf_predictions))).mean()\n",
        "word_rmse_rf = math.sqrt(((np.array(y_naive_test)-np.array(word_ml_rf_predictions))**2).mean())\n",
        "\n",
        "print(\"RANDOM MAE: %.3f\" %word_mae_rf)\n",
        "print(\"RANDOM RMSE: %.3f\" %word_rmse_rf)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}